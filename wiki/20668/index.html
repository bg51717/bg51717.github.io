<!DOCTYPE html>
<html lang=zh>
<head>
    <meta charset="utf-8">
    <meta name="google-site-verification" content="umJh1MKBdH4dUlHcpYXkGto1Vw4htN34qeA2NX-Eey8" />
    
    <title>pytroch_tutorials杂项 | Blogs</title>
    
    
        <meta name="keywords" content="pytroch_tutorials" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="介绍 当作快速过这个资料的笔记，一些关于别的库的介绍是不完全的，考虑在使用的时候从别的信息渠道就行信息的搜集。也可以作为后面待更博客列举？ 具体 torchscript Introduction to TorchScript — PyTorch Tutorials 2.2.1+cu121 documentation Loading a TorchScript Model in C++ — PyTo">
<meta property="og:type" content="article">
<meta property="og:title" content="pytroch_tutorials杂项">
<meta property="og:url" content="https://bg51717.github.io/wiki/20668/">
<meta property="og:site_name" content="Blogs">
<meta property="og:description" content="介绍 当作快速过这个资料的笔记，一些关于别的库的介绍是不完全的，考虑在使用的时候从别的信息渠道就行信息的搜集。也可以作为后面待更博客列举？ 具体 torchscript Introduction to TorchScript — PyTorch Tutorials 2.2.1+cu121 documentation Loading a TorchScript Model in C++ — PyTo">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-12-29T08:23:43.000Z">
<meta property="article:modified_time" content="2024-11-02T02:55:49.878Z">
<meta property="article:author" content="bg51717">
<meta property="article:tag" content="pytroch_tutorials">
<meta name="twitter:card" content="summary">
    

    
        <link rel="alternate" href="/atom.xml" title="Blogs" type="application/atom+xml" />
    

    
        <link rel="icon" href="/wiki/favicon.ico" />
    

    
<link rel="stylesheet" href="/wiki/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/wiki/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/wiki/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/wiki/css/style.css">

    
<script src="/wiki/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/wiki/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/wiki/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/wiki/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" />
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/wiki/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Blogs</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/wiki/">首页</a>
                
                    <a class="main-nav-link" href="/wiki/archives">归档</a>
                
                    <a class="main-nav-link" href="/wiki/categories">分类</a>
                
                    <a class="main-nav-link" href="/wiki/tags">标签</a>
                
                    <a class="main-nav-link" href="/wiki/about">关于</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/wiki/',
        CONTENT_URL: '/wiki/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/wiki/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/wiki/">首页</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>分类</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            SmallProjects
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            博客搭建
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/13640/">Hexo+Github搭建个人Wiki风格博客</a></li>  <li class="file"><a href="/wiki/31680/">hexo博客2:双主题</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            huggingface
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/20669/">pytroch_tutorials杂项</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            工具
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/44392/">快速启动工具——utools</a></li>  <li class="file"><a href="/wiki/43151/">文献管理工具zotero</a></li>  <li class="file"><a href="/wiki/61294/">安卓手机配置Google</a></li>  <li class="file"><a href="/wiki/13107/">zsh+powerlevel10K优化终端使用体验</a></li>  <li class="file"><a href="/wiki/13162/">使用dotbot快速同步Linux配置</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            数学
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            微积分
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/49444/">拉格朗日乘数法解条件极值</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            概率论
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/5656/">信息熵</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            线性代数
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/45525/">矩阵偏分</a></li>  <li class="file"><a href="/wiki/33996/">矩阵奇异值分解SVD</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            杂项
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file active"><a href="/wiki/20668/">pytroch_tutorials杂项</a></li>  <li class="file"><a href="/wiki/30403/">vscode调试python</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            模板
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/42347/">pytorch_model</a></li>  <li class="file"><a href="/wiki/61054/">PyTorch代码转HF</a></li>  <li class="file"><a href="/wiki/45014/">pytorch分布式-ddp</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            深度学习
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            工程细节
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/7369/">随机数种子</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            经典模块
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/12551/">Adam Optimizer</a></li>  <li class="file"><a href="/wiki/13277/">梯度估计STE</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            自然语言处理
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/5925/">Word2Vec</a></li>  <li class="file"><a href="/wiki/51558/">GloVe</a></li>  <li class="file"><a href="/wiki/26708/">依赖分析Dependency Parsing</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            科研
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            论文阅读
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/62023/">论文阅读:A_Survey_of_Quantization_Methods_for_Efficient_Neural_Network_Inference</a></li>  <li class="file"><a href="/wiki/8948/">论文阅读:BitNet_Scaling_1-bit_Transformers_for_Large_Language_Models</a></li>  <li class="file"><a href="/wiki/21264/">llm.int8</a></li>  <li class="file"><a href="/wiki/31769/">大模型量化~GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a></li>  <li class="file"><a href="/wiki/14592/">AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a></li>  <li class="file"><a href="/wiki/341/">OneBit: Towards Extremely Low-bit Large Language Models</a></li>  <li class="file"><a href="/wiki/58958/">OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models</a></li>  <li class="file"><a href="/wiki/22407/">论文阅读习惯</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            自然语言处理
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/63314/">nlp常用排行榜</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            课程资源
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/17140/">readme</a></li>  </ul> 
                    </li> 
                     <li class="file"><a href="/wiki/14261/">Welcome to bg51717's Wiki and Blog</a></li>  </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-杂项/pytroch_tutorials杂项" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/wiki/categories/%E6%9D%82%E9%A1%B9/">杂项</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/wiki/tags/pytroch-tutorials/" rel="tag">pytroch_tutorials</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/wiki/20668/">
            <time datetime="2023-12-29T08:23:43.000Z" itemprop="datePublished">2023-12-29</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/bg51717/Wiki-site/raw/writing/source/_posts/杂项/pytroch_tutorials杂项.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/bg51717/Wiki-site/edit/writing/source/_posts/杂项/pytroch_tutorials杂项.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/bg51717/Wiki-site/commits/writing/source/_posts/杂项/pytroch_tutorials杂项.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            pytroch_tutorials杂项
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">文章目录</strong>
                    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E4%BD%93"><span class="toc-number">2.</span> <span class="toc-text">具体</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#torchscript"><span class="toc-number">2.1.</span> <span class="toc-text">torchscript</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#onnx"><span class="toc-number">2.2.</span> <span class="toc-text">ONNX</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%96%E6%9E%90pytorch-model"><span class="toc-number">2.3.</span> <span class="toc-text">剖析pytorch model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#troch.fx-%E6%93%8D%E4%BD%9C%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="toc-number">2.4.</span> <span class="toc-text">troch.fx 操作计算图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E7%BB%84%E7%BB%87"><span class="toc-number">2.5.</span> <span class="toc-text">存储组织</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E6%A8%A1%E5%BC%8F%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86"><span class="toc-number">2.6.</span> <span class="toc-text">前向模式自动微分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%AE%E5%88%86%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97"><span class="toc-number">2.7.</span> <span class="toc-text">微分矩阵计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%84%E8%A3%85"><span class="toc-number">2.8.</span> <span class="toc-text">模型组装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E6%A0%B7%E6%9C%AC%E6%A2%AF%E5%BA%A6"><span class="toc-number">2.9.</span> <span class="toc-text">单样本梯度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#c%E6%8E%A5%E5%8F%A3"><span class="toc-number">2.10.</span> <span class="toc-text">c++接口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torchscript-%E4%B8%AD%E7%9A%84%E5%8A%A8%E6%80%81%E5%B9%B6%E8%A1%8C%E6%80%A7"><span class="toc-number">2.11.</span> <span class="toc-text">TorchScript 中的动态并行性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#c%E6%8E%A5%E5%8F%A3%E4%B8%AD%E7%9A%84%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC"><span class="toc-number">2.12.</span> <span class="toc-text">c++接口中的自动求导</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%99%E9%87%8C%E9%83%BD%E6%98%AF%E4%B8%80%E4%BA%9B%E7%94%A8c%E6%89%A9%E5%B1%95pytorch%E7%9A%84%E5%86%85%E5%AE%B9%E5%90%8E%E9%9D%A2%E9%9C%80%E8%A6%81%E7%BB%86%E8%87%B4%E5%AD%A6%E4%B9%A0%E6%8C%96%E5%9D%91todo"><span class="toc-number">2.13.</span> <span class="toc-text">这里都是一些用c++扩展pytorch的内容，后面需要细致学习（挖坑todo</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%E6%B1%82%E4%BA%8C%E9%98%B6%E5%AF%BC"><span class="toc-number">2.14.</span> <span class="toc-text">自定义函数求二阶导</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0%E5%8D%B7%E7%A7%AF"><span class="toc-number">2.15.</span> <span class="toc-text">自定义函数实现卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89-c-%E5%92%8C-cuda-%E6%89%A9%E5%B1%95"><span class="toc-number">2.16.</span> <span class="toc-text">自定义 C++ 和 CUDA 扩展</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89-c-%E8%BF%90%E7%AE%97%E7%AC%A6%E6%89%A9%E5%B1%95-torchscript"><span class="toc-number">2.17.</span> <span class="toc-text">使用自定义 C++ 运算符扩展
TorchScript</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89-c-%E7%B1%BB%E6%89%A9%E5%B1%95-torchscript"><span class="toc-number">2.18.</span> <span class="toc-text">使用自定义 C++ 类扩展
TorchScript</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8c%E4%B8%AD%E6%B3%A8%E5%86%8C%E4%B8%80%E4%B8%AA%E5%88%86%E6%B4%BE%E6%93%8D%E4%BD%9C%E7%AC%A6"><span class="toc-number">2.19.</span> <span class="toc-text">在C++中注册一个分派操作符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8-c-%E4%B8%AD%E6%89%A9%E5%B1%95%E6%96%B0%E5%90%8E%E7%AB%AF%E7%9A%84%E8%B0%83%E5%BA%A6%E7%A8%8B%E5%BA%8F"><span class="toc-number">2.20.</span> <span class="toc-text">在 C++ 中扩展新后端的调度程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E5%90%88tensorboard%E7%9A%84profiler"><span class="toc-number">2.21.</span> <span class="toc-text">结合tensorboard的profiler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8ray-tune%E8%BF%9B%E8%A1%8C%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98"><span class="toc-number">2.22.</span> <span class="toc-text">使用Ray Tune进行超参数调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96vision-transformer%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.23.</span> <span class="toc-text">优化Vision Transformer模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E5%8C%96%E6%95%99%E7%A8%8B"><span class="toc-number">2.24.</span> <span class="toc-text">参数化教程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%AA%E6%9E%9D%E6%95%99%E7%A8%8B"><span class="toc-number">2.25.</span> <span class="toc-text">剪枝教程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E9%87%8F%E5%8C%96"><span class="toc-number">2.26.</span> <span class="toc-text">动态量化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9A%84%E9%87%8F%E5%8C%96%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B"><span class="toc-number">2.27.</span> <span class="toc-text">计算机视觉的量化迁移学习教程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pytorch-%E4%B8%AD%E5%85%B7%E6%9C%89-eager-%E6%A8%A1%E5%BC%8F%E7%9A%84%E9%9D%99%E6%80%81%E9%87%8F%E5%8C%96"><span class="toc-number">2.28.</span> <span class="toc-text">PyTorch 中具有 Eager
模式的静态量化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E7%AC%AC%E4%B8%80%E6%80%A7%E5%8E%9F%E7%90%86%E6%8C%96%E6%8E%98-pytorch-intel-cpu-%E6%80%A7%E8%83%BD"><span class="toc-number">2.29.</span> <span class="toc-text">从第一性原理挖掘
PyTorch Intel CPU 性能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%A6-ax-%E7%9A%84%E5%A4%9A%E7%9B%AE%E6%A0%87-nas"><span class="toc-number">2.30.</span> <span class="toc-text">带 Ax 的多目标 NAS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch.compile%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.31.</span> <span class="toc-text">torch.compile介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#inductor-cpu-backend-debugging-and-profiling"><span class="toc-number">2.32.</span> <span class="toc-text">Inductor CPU
backend debugging and profiling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9Btransformer"><span class="toc-number">2.33.</span> <span class="toc-text">实现高效缩放点积注意力Transformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F"><span class="toc-number">2.34.</span> <span class="toc-text">知识蒸馏</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E6%8C%96%E5%9D%91todo"><span class="toc-number">2.35.</span> <span class="toc-text">分布式（挖坑todo</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">2.36.</span> <span class="toc-text">参考资料</span></a></li></ol></li></ol>
                </div>
            
        
        
            <h2 id="介绍">介绍</h2>
<p>当作快速过这个资料的笔记，一些关于别的库的介绍是不完全的，考虑在使用的时候从别的信息渠道就行信息的搜集。也可以作为后面待更博客列举？</p>
<h2 id="具体">具体</h2>
<h3 id="torchscript">torchscript</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">Introduction
to TorchScript — PyTorch Tutorials 2.2.1+cu121 documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/cpp_export.html">Loading a
TorchScript Model in C++ — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这里介绍了把pytorch模型转换成torchscript的两种方法torch.jit.trace和torch.jit.script，前者会失去控制流信息，后者会保留控制流信息（具体查阅文档）。</p>
<p>转化为torchscript有以下好处：</p>
<ul>
<li>不需要Python解释器也可以运行，可以被pytorch自带的特殊解释器直接使用</li>
<li>转为torchscript可以进行各种优化，提高运行效率</li>
<li>方便被其他语言调用</li>
</ul>
<h3 id="onnx">ONNX</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html">(optional)
Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime
— PyTorch Tutorials 2.2.1+cu121 documentation</a></p>
<p>这里介绍了在高效且跨平台ONNX运行环境部署的基本教程，通过torch.onnx把模型转化为onnx格式并保存，然后读取本地保存onnx格式模型并运行。</p>
<h3 id="剖析pytorch-model">剖析pytorch model</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/profiler.html">Profiling
your PyTorch Module — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这里介绍了torch.autograd.profiler,在代码里添加with
profiler.record_function("MASK
INDICES"):可以记录代码运行的指标，比如时间，cpu和内存使用率等，名字可以自定义，支持可视化结果。</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/hta_intro_tutorial.html">Introduction
to Holistic Trace Analysis — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/hta_trace_diff_tutorial.html">Trace
Diff using Holistic Trace Analysis — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这里介绍了HolisticTraceAnalysis（HTA），一个用来剖析GPU运行情况的库。</p>
<p>把GPU运行时间分为了等待时间、计算时间和非计算时间，方便开发者评测模型运行的情况。还支持查看GPU内部的运行情况，也支持和之前的记录进行对比，也能可视化结果。</p>
<h3 id="troch.fx-操作计算图">troch.fx 操作计算图</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/fx_conv_bn_fuser.html">（测试版）在
FX 中构建卷积/批量范数热熔器 — PyTorch 教程 2.2.1+cu121 文档</a></p>
<p><code>torch.fx</code> 是 PyTorch
提供的一个模块，它允许用户通过操作计算图来转换和优化 PyTorch
模型。这个模块提供了一种方式来表示和操作 PyTorch
模型的抽象，使得开发者可以更容易地对模型进行修改，例如重构模型结构、插入调试代码、优化性能等。</p>
<p>教程里介绍了一种融合相邻层的操作（只能用于eval模式）。比如融合卷积和归一化，融合之前，模型会把卷积结果写回显存，然后在调用归一化并且从显存读取之前结果；融合后变成一种操作，卷积结果不会写回显存，而是直接进行归一化后写会显存。</p>
<figure class="highlight python-repl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">def _parent_name(target : str) -&gt; Tuple[str, str]:</span><br><span class="line">    """</span><br><span class="line">    Splits a ``qualname`` into parent path and last atom.</span><br><span class="line">    For example, `foo.bar.baz` -&gt; (`foo.bar`, `baz`)</span><br><span class="line">    """</span><br><span class="line">    *parent, name = target.rsplit('.', 1)</span><br><span class="line">    return parent[0] if parent else '', name</span><br><span class="line"></span><br><span class="line">def replace_node_module(node: fx.Node, modules: Dict[str, Any], new_module: torch.nn.Module):</span><br><span class="line">    assert(isinstance(node.target, str))</span><br><span class="line">    parent_name, name = _parent_name(node.target)</span><br><span class="line">    setattr(modules[parent_name], name, new_module)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def fuse(model: torch.nn.Module) -&gt; torch.nn.Module:</span><br><span class="line">    model = copy.deepcopy(model)</span><br><span class="line">    # The first step of most FX passes is to symbolically trace our model to</span><br><span class="line">    # obtain a `GraphModule`. This is a representation of our original model</span><br><span class="line">    # that is functionally identical to our original model, except that we now</span><br><span class="line">    # also have a graph representation of our forward pass.</span><br><span class="line">    #获取计算图</span><br><span class="line">    fx_model: fx.GraphModule = fx.symbolic_trace(model)</span><br><span class="line">    modules = dict(fx_model.named_modules())</span><br><span class="line"></span><br><span class="line">    # The primary representation for working with FX are the `Graph` and the</span><br><span class="line">    # `Node`. Each `GraphModule` has a `Graph` associated with it - this</span><br><span class="line">    # `Graph` is also what generates `GraphModule.code`.</span><br><span class="line">    # The `Graph` itself is represented as a list of `Node` objects. Thus, to</span><br><span class="line">    # iterate through all of the operations in our graph, we iterate over each</span><br><span class="line">    # `Node` in our `Graph`.</span><br><span class="line">    #枚举所有计算图节点</span><br><span class="line">    for node in fx_model.graph.nodes:</span><br><span class="line">        # The FX IR contains several types of nodes, which generally represent</span><br><span class="line">        # call sites to modules, functions, or methods. The type of node is</span><br><span class="line">        # determined by `Node.op`.</span><br><span class="line">	#计算图节点还有别的属性,具体可以查阅相关资料</span><br><span class="line">        if node.op != 'call_module': # If our current node isn't calling a Module then we can ignore it.</span><br><span class="line">            continue</span><br><span class="line">        # For call sites, `Node.target` represents the module/function/method</span><br><span class="line">        # that's being called. Here, we check `Node.target` to see if it's a</span><br><span class="line">        # batch norm module, and then check `Node.args[0].target` to see if the</span><br><span class="line">        # input `Node` is a convolution.</span><br><span class="line">	#modules指的是模块,node.target指的是节点名字,node.args应该指的是输入这个节点的前置节点</span><br><span class="line">        if type(modules[node.target]) is nn.BatchNorm2d and type(modules[node.args[0].target]) is nn.Conv2d:</span><br><span class="line">            if len(node.args[0].users) &gt; 1:  # Output of conv is used by other nodes</span><br><span class="line">                continue</span><br><span class="line">            conv = modules[node.args[0].target]</span><br><span class="line">            bn = modules[node.target]</span><br><span class="line">            fused_conv = fuse_conv_bn_eval(conv, bn)</span><br><span class="line">            replace_node_module(node.args[0], modules, fused_conv)</span><br><span class="line">            # As we've folded the batch nor into the conv, we need to replace all uses</span><br><span class="line">            # of the batch norm with the conv.</span><br><span class="line">	    #把使用到node节点输出的地方变成node.args[0]节点输出</span><br><span class="line">            node.replace_all_uses_with(node.args[0])</span><br><span class="line">            # Now that all uses of the batch norm have been replaced, we can</span><br><span class="line">            # safely remove the batch norm.</span><br><span class="line">            fx_model.graph.erase_node(node)</span><br><span class="line">    #检查计算图（Graph）的完整性和一致性,确定计算图的正确性</span><br><span class="line">    fx_model.graph.lint()</span><br><span class="line">    # After we've modified our graph, we need to recompile our graph in order</span><br><span class="line">    # to keep the generated code in sync.</span><br><span class="line">    #recompile()方法的作用是将这些修改后的计算图转换回 Python 代码，这样你就可以创建一个新的 PyTorch 模型实例，它包含了你所做的所有修改</span><br><span class="line">    fx_model.recompile()</span><br><span class="line">    return fx_model</span><br></pre></td></tr></tbody></table></figure>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/fx_profiling_tutorial.html">（测试版）使用
FX 构建简单的 CPU 性能分析器 — PyTorch 教程 2.2.1+cu121 文档</a></p>
<p>通过
<code>print(traced_rn18.graph)</code>我们可以查看计算图的信息，这里只选择一行查看，例子:</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%layer1_1_conv2 : [num_users=1] = call_module[target=layer1.1.conv2](args = (%layer1_1_relu,), kwargs = {})</span><br><span class="line">%layer1_1_conv2:节点名字,</span><br><span class="line">[num_users=1]:被几个后续节点使用,</span><br><span class="line">call_module:表面这是一个调用模块,</span><br><span class="line">target=layer1.1.conv2:调用模块的名字,</span><br><span class="line">args = (%layer1_1_relu,):传递给模块的参数(输入模块的之前节点)</span><br><span class="line">kwargs = {}:额外关键词参数</span><br></pre></td></tr></tbody></table></figure>
<p>可以参照教程写一个继承torch.fx.Interpreter的类,重写run和run_node实现对于计算图的捕获，在运行过程中添加自定义行为。</p>
<h3 id="存储组织">存储组织</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html">(beta)
Channels Last Memory Format in PyTorch — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这里介绍了内存组织方式torch.channels_last，torch.contiguous_format等，同时介绍了一下torch.stride、torch.contiguous和torch.is_contiguous等函数。</p>
<p>有的操作符会保留内存组织格式。</p>
<p>可以通过model.to(memory_format=)把模型转化为适合的组织形式，同时输入也需要相应的转换（框架应该支持自动转换？）。</p>
<p>但由于不是所有的操作符都支持某种内存组织格式，可能需要进行检查，这里给了检查和设置的示例代码。</p>
<h3 id="前向模式自动微分">前向模式自动微分</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/forward_ad_usage.html">正向模式自动微分
（Beta） — PyTorch 教程 2.2.1+cu121 文档</a></p>
<p>这里看的不是很明白。挖个坑（todo...</p>
<p>正向传播一次只能算出相对一个参数的梯度，如果有n个参数，需要计算n次，所以这里的tangent只有一个，而不是每个参数对应一个。</p>
<p>可以参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/518296942">【自动微分原理】AD的正反向模式
- 知乎 (zhihu.com)</a>。</p>
<p>（这么一看，正向自动微分被方向自动微分爆杀？目前应用少且pytorch也只是测试版本</p>
<h3 id="微分矩阵计算">微分矩阵计算</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/jacobians_hessians.html">雅可比派、黑森派、hvp、vhp
等：编写函数转换 — PyTorch 教程 2.2.1+cu121 文档</a></p>
<p>这里提供了各种使用自动求导计算微分矩阵的方法。</p>
<h3 id="模型组装">模型组装</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/ensembling.html">模型组装
— PyTorch 教程 2.2.1+cu121 文档</a></p>
<p>这里介绍了torch.func.stack_model_state、torch.vmap等函数用来组装一系列结构相同参数不同的模型的输出，类似于使用cat连接模型输出，但是增加了底层优化。</p>
<h3 id="单样本梯度">单样本梯度</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/per_sample_grads.html">Per-sample-gradients
— PyTorch 教程 2.2.1+cu121 文档</a></p>
<p>在一些要求对每个样本单独计算梯度的特殊情况下，可以使用本篇介绍的方法优化速度。</p>
<p>这里介绍了torch.func.grad、torch.func.functional_call、torch.func.vmap来优化加速（注意不同库有不同的同名函数）</p>
<p>这里grad和vmap都是创建的可调用对象，与别的同名函数不同。</p>
<h3 id="c接口">c++接口</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/cpp_frontend.html">Using
the PyTorch C++ Frontend — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>介绍了怎么使用c++调用</p>
<h3 id="torchscript-中的动态并行性">TorchScript 中的动态并行性</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/torch-script-parallelism.html">TorchScript
中的动态并行性 — PyTorch 教程 2.2.1+cu121 文档</a></p>
<p>这里介绍了torch.jit.fork和torch.jit.wait两个函数用来并行执行pytorch相关代码。同时也引入了相关的类torch.jit.Future。</p>
<h3 id="c接口中的自动求导">c++接口中的自动求导</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/cpp_autograd.html">Autograd
in C++ Frontend — PyTorch Tutorials 2.2.1+cu121 documentation</a></p>
<h3 id="这里都是一些用c扩展pytorch的内容后面需要细致学习挖坑todo">这里都是一些用c++扩展pytorch的内容，后面需要细致学习（挖坑todo</h3>
<h3 id="自定义函数求二阶导">自定义函数求二阶导</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/custom_function_double_backward_tutorial.html">Double
Backward with Custom Functions — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这篇文章介绍了怎么使用继承自torch.autograd.Function的自定义函数（重新forward和backward），计算导数，并且用torch.autograd.gradcheck使用数值解验证求导以及使用torchviz
可视化图形。</p>
<p>同时，注意在运行过程中，保存求导所需要参数时候建议按照教程分保存输入、保存输出和保存中间结果考虑代码结构，避免bug。</p>
<p>forward函数返回结果似乎和backward参数对应，backward输入参数是每个forward函数返回结果的grad。</p>
<p>保存中间结果的时候需要把中间结果返回，这样可以让pytorch的自动微分系统追踪这些中间结果（个人理解为返回中间结果相当于注册了这些中间结果，在backward的时候设置grad模型就会追踪这些中间结果，理解可能有误，但是使用的时候参考教程应该问题不大）。</p>
<h3 id="自定义函数实现卷积">自定义函数实现卷积</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/custom_function_conv_bn_tutorial.html">Fusing
Convolution and Batch Norm using Custom Function — PyTorch Tutorials
2.2.1+cu121 documentation</a></p>
<p>先介绍了自定义卷积函数的构造，这里的once_differentiable指的是正向传播的结果只会反向传播一次，作用为求二阶导的时候会报错，从而起到限制的作用。</p>
<p>然后介绍了自定义批量归一化层的构造，然后介绍了自定义函数混合卷积和批量归一化，从而实现了节省内存的作用。</p>
<h3 id="自定义-c-和-cuda-扩展">自定义 C++ 和 CUDA 扩展</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/cpp_extension.html">Custom
C++ and CUDA Extensions — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这里介绍了两个扩展c++组件的方法，“ahead of time ”和“just in
time”。</p>
<p>ahead of
time：构建setup.py文件用于构建c++扩展，然后在对应的cpp文件里面构建c++扩展代码。</p>
<p>just in
time:通过torch.utils.cpp_extension.load直接加载cpp文件，会把编译的中间文件存在一个临时目录里。</p>
<p>这里还介绍了编写混合 C++/CUDA
扩展，由于还没有学过cuda，挖个坑todu...</p>
<h3 id="使用自定义-c-运算符扩展-torchscript">使用自定义 C++ 运算符扩展
TorchScript</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html">Extending
TorchScript with Custom C++ Operators — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>如题，后面需要细致学习todo,,,</p>
<h3 id="使用自定义-c-类扩展-torchscript">使用自定义 C++ 类扩展
TorchScript</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/torch_script_custom_classes.html">Extending
TorchScript with Custom C++ Classes — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>如题，后面需要细致学习todo,,,</p>
<h3 id="在c中注册一个分派操作符">在C++中注册一个分派操作符</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/dispatcher.html">Registering
a Dispatched Operator in C++ — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>由于一个操作在不同的设备上对应不同的底层代码，所以为了抽象化其操作，方便调用，需要在内核注册对应设备对应函数，然后在调用。</p>
<p>比如，第一个把 <code>myadd_cpu</code>注册到cpu上的
<code>myadd</code>函数，当在cpu上运行 <code>myadd</code>函数时候，会调用
<code>myadd_cpu</code></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TORCH_LIBRARY_IMPL(myops, CPU, m) {</span><br><span class="line">  m.impl("myadd", myadd_cpu);</span><br><span class="line">}</span><br><span class="line">TORCH_LIBRARY_IMPL(myops, CUDA, m) {</span><br><span class="line">  m.impl("myadd", myadd_cuda);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>然后在使用的时候，通过torch的调度器自动根据设备在内核寻找合适函数调用。</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Tensor myadd(const Tensor&amp; self, const Tensor&amp; other) {</span><br><span class="line">  static auto op = torch::Dispatcher::singleton()</span><br><span class="line">    .findSchemaOrThrow("myops::myadd", "")</span><br><span class="line">    .typed&lt;decltype(myadd)&gt;();</span><br><span class="line">  return op.call(self, other);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>这里还介绍了自动投影机制autocast，用于在运算之前把精度投影到合适的精度。</p>
<h3 id="在-c-中扩展新后端的调度程序">在 C++ 中扩展新后端的调度程序</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/extend_dispatcher.html">Extending
dispatcher for a new backend in C++ — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>后端（backend）通常指的是支持PyTorch运行的底层系统或框架，这里介绍了如何添加自定义的框架。(大致是需要实现一些基本的运算，别的运算可以表示成这样运算的组合)。</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/privateuseone.html">Facilitating
New Backend Integration by PrivateUse1 — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这里介绍了使用privateuse1注册新后端的流程。</p>
<h3 id="结合tensorboard的profiler">结合tensorboard的profiler</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html">PyTorch
Profiler With TensorBoard — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这篇文章介绍了profiler结合tensorboard的使用。</p>
<h3 id="使用ray-tune进行超参数调优">使用Ray Tune进行超参数调优</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html">Hyperparameter
tuning with Ray Tune — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这篇文章介绍了怎么使用Ray Tune库进行超参数的搜索。</p>
<h3 id="优化vision-transformer模型">优化Vision Transformer模型</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/vt_tutorial.html">Optimizing
Vision Transformer Model for Deployment — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这篇文章介绍了怎么去优化Vision
Transformer模型，列举了一些常见的优化方式。</p>
<h3 id="参数化教程">参数化教程</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/parametrizations.html">Parametrizations
Tutorial — PyTorch Tutorials 2.2.1+cu121 documentation</a></p>
<p>这里的参数化指的是类似于对模型部分权重使用的一种限制，应该是在参数修改后调用（比如初始化，参数更新等）的一些nn.module，从而使得模型更加灵活，实现对不同参数的不同处理过程，具体使用过程也是看教程，进行类的注册，使用函数parametrize。</p>
<p>with parametrize.cached():可以开启参数的缓存模型。</p>
<p>可以对于一个参数注册多个参数化模块。</p>
<p>同时参数化模块内部有的函数可以只在特殊时期调用，比如初始化。</p>
<p>可以移除参数化模块。</p>
<h3 id="剪枝教程">剪枝教程</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/pruning_tutorial.html">Pruning
Tutorial — PyTorch Tutorials 2.2.1+cu121 documentation</a></p>
<p>这里介绍了剪枝和机制，以及钩子函数的引入。</p>
<p>介绍了组合剪枝，通过移除重参数化来永久化剪枝，不同模块针对剪枝，全局剪枝，扩展自己的剪枝函数等。</p>
<h3 id="动态量化">动态量化</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/dynamic_quantization_tutorial.html">(beta)
Dynamic Quantization on an LSTM Word Language Model — PyTorch Tutorials
2.2.1+cu121 documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/dynamic_quantization_bert_tutorial.html">(beta)
Dynamic Quantization on BERT — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这里介绍了使用torch.quantization.quantize_dynamic动态量化一次常见模型的例子。</p>
<h3 id="计算机视觉的量化迁移学习教程">计算机视觉的量化迁移学习教程</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/quantized_transfer_learning_tutorial.html">(beta)
Quantized Transfer Learning for Computer Vision Tutorial — PyTorch
Tutorials 2.2.1+cu121 documentation</a></p>
<p>这篇文章介绍了在微调时候插入量化模拟层和反量化层，从而让模型适应量化的过程（QAT）。</p>
<h3 id="pytorch-中具有-eager-模式的静态量化">PyTorch 中具有 Eager
模式的静态量化</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html">(beta)
Static Quantization with Eager Mode in PyTorch — PyTorch Tutorials
2.2.1+cu121 documentation</a></p>
<p>这个教程演示如何进行训练后静态量化，并说明两种更先进的技术，通道量化和量化感知训练。</p>
<h3 id="从第一性原理挖掘-pytorch-intel-cpu-性能">从第一性原理挖掘
PyTorch Intel CPU 性能</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/torchserve_with_ipex.html">Grokking
PyTorch Intel CPU performance from first principles — PyTorch Tutorials
2.2.1+cu121 documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/torchserve_with_ipex_2.html">Grokking
PyTorch Intel CPU performance from first principles (Part 2) — PyTorch
Tutorials 2.2.1+cu121 documentation</a></p>
<p>这里介绍了优化CPU性能的方法和原理，目前来说太高深（挖矿todo</p>
<h3 id="带-ax-的多目标-nas">带 Ax 的多目标 NAS</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/ax_multiobjective_nas_tutorial.html">Multi-Objective
NAS with Ax — PyTorch Tutorials 2.2.1+cu121 documentation</a></p>
<p>这篇文章介绍了怎么使用Ax平台进行神经网络架构的搜索。</p>
<h3 id="torch.compile介绍">torch.compile介绍</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html">Introduction
to torch.compile — PyTorch Tutorials 2.2.1+cu121 documentation</a></p>
<p>可以使用torch.compile当做装饰器或者函数使用。</p>
<p>同时也列举了几个模式以及和别的几个优化方法的对比。</p>
<h3 id="inductor-cpu-backend-debugging-and-profiling">Inductor CPU
backend debugging and profiling</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/inductor_debug_cpu.html">Inductor
CPU backend debugging and profiling — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这篇文章介绍了怎么对C++后端进行debug和profile的过程。有点复杂，，，（挖坑todo</p>
<h3 id="实现高效缩放点积注意力transformer">实现高效缩放点积注意力Transformer</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/intermediate/scaled_dot_product_attention_tutorial.html">(Beta)
Implementing High-Performance Transformers with Scaled Dot Product
Attention (SDPA) — PyTorch Tutorials 2.2.1+cu121 documentation</a></p>
<p>这篇文章介绍了怎么优化使用常用的缩放点积注意力。</p>
<p>torch.nested.nested_tensor支持融合不同长度的张量。</p>
<h3 id="知识蒸馏">知识蒸馏</h3>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html">Knowledge
Distillation Tutorial — PyTorch Tutorials 2.2.1+cu121
documentation</a></p>
<p>这篇教程介绍了知识蒸馏的几个方式，主要都是在损失函数里面添加教师模型和学生模型的各种量化差异来训练学生模型。</p>
<h3 id="分布式挖坑todo">分布式（挖坑todo</h3>
<h3 id="参考资料">参考资料</h3>
<blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/">Welcome to PyTorch
Tutorials — PyTorch Tutorials 2.2.1+cu121 documentation</a></li>
</ul>
</blockquote>

            </div>
        

        
    
        <section id="comments"> 
        <!-- 公告区域 -->
        <div id="announcement" style="background-color: #f8d7da; color: #721c24; padding: 10px; text-align: center; font-weight: bold; border-radius: 15px;">
            由于评论系统依托于Github的Discuss存在，因此默认评论者会收到所有通知。可以在邮件里点击"unsubscribe"停止接受，后续也可以点击下列仓库进行通知管理：
            <a href="https://github.com/bg51717/Hexo-Blogs-comments" target="_blank" style="color: #0056b3; text-decoration: underline; white-space: nowrap;">
                bg51717/Hexo-Blogs-comments
            </a>
            <br>
            Since the comment system relies on GitHub's Discussions feature, by default, commentators will receive all notifications. You can click "unsubscribe" in the email to stop receiving them, and you can also manage your notifications by clicking on the following repositories:
            <a href="https://github.com/bg51717/Hexo-Blogs-comments" target="_blank" style="color: #0056b3; text-decoration: underline; white-space: nowrap;">
                bg51717/Hexo-Blogs-comments
            </a>
        </div>
        
        <!-- Giscus 评论组件 -->
        <div id="giscus-container"></div>
        <script src="https://giscus.app/client.js"
                data-repo="bg51717/Hexo-Blogs-comments"
                data-repo-id="R_kgDOKhgfLA"
                data-category="General"
                data-category-id="DIC_kwDOKhgfLM4CaPMJ"
                data-mapping="title"
                data-strict="0"
                data-reactions-enabled="1"
                data-emit-metadata="0"
                data-input-position="top"
                data-theme="light"
                data-lang="zh-CN"
                data-loading="lazy"
                crossorigin="anonymous"
                async>
        </script>
        <noscript>请启用 JavaScript 以查看评论。</noscript>
     </section>
    



        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/wiki/5656/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    信息熵
                
            </div>
        </a>
    
    
        <a href="/wiki/12551/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">Adam Optimizer</div>
        </a>
    
</nav>






<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            bg51717 &copy; 2024 
            <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a target="_blank" rel="noopener" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        <!-- partial('comment/scripts', { page: page })  -->

    
        
<script src="/wiki/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/wiki/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
    
        
    <!-- 引入 KaTeX 的 CSS 文件 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css">
    
    <!-- 引入 KaTeX 的 JS 文件 -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js"></script>

    <script>
        document.addEventListener("DOMContentLoaded", function() {
            // 自动渲染公式
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},  // 行间公式
                    {left: "$", right: "$", display: false},   // 行内公式
                    {left: "\\(", right: "\\)", display: false}, // 行内公式
                    {left: "\\[", right: "\\]", display: true}  // 行间公式
                ],
                ignoredTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],  // 跳过这些标签
                throwOnError: false  // 遇到无法解析的公式时不抛出错误
            });

            // 判断是否需要隐藏滚动条
            var hideScrollbar = false;
            if (hideScrollbar) {
                const katexElements = document.querySelectorAll('.katex-display');
                katexElements.forEach(function(el) {
                    el.style.overflowX = 'hidden';
                });
            }

            // 给含有 KaTeX 公式的元素添加类名 'has-katex'，类似 MathJax 的 'has-jax'
            var katexElements = document.querySelectorAll('.katex');
            katexElements.forEach(function(el) {
                el.classList.add('has-katex');
            });
        });
    </script>


    



<!-- Custom Scripts -->

<script src="/wiki/js/main.js"></script>


    </div>
</body>
</html>