<!DOCTYPE html>
<html lang=zh>
<head>
    <meta charset="utf-8">
    <meta name="google-site-verification" content="umJh1MKBdH4dUlHcpYXkGto1Vw4htN34qeA2NX-Eey8" />
    
    <title>论文阅读:BitNet_Scaling_1-bit_Transformers_for_Large_Language_Models | Blogs</title>
    
    
        <meta name="keywords" content="量化" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="摘要 这篇论文展示了BitNet,一种为大型语言模型设计的可扩展和稳定的1-bit转换器架构。具体地说，引入了BitLinear作为nn.Linar的插入替代,以便从头开始训练1-bit的权重。在语言建模上的实验结果表明，与最先进的8-bit量化方法和FP16 Transformer相比，BitNet在显著降低内存占用和能量消耗的同时，实现了强力的性能。此外，BitNet还展示了一种类似于全精度T">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读:BitNet_Scaling_1-bit_Transformers_for_Large_Language_Models">
<meta property="og:url" content="https://bg51717.github.io/wiki/8948/">
<meta property="og:site_name" content="Blogs">
<meta property="og:description" content="摘要 这篇论文展示了BitNet,一种为大型语言模型设计的可扩展和稳定的1-bit转换器架构。具体地说，引入了BitLinear作为nn.Linar的插入替代,以便从头开始训练1-bit的权重。在语言建模上的实验结果表明，与最先进的8-bit量化方法和FP16 Transformer相比，BitNet在显著降低内存占用和能量消耗的同时，实现了强力的性能。此外，BitNet还展示了一种类似于全精度T">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://bg51717.github.io/wiki/8948/1698064373146.png">
<meta property="og:image" content="https://bg51717.github.io/wiki/8948/1730709381779.png">
<meta property="og:image" content="https://bg51717.github.io/wiki/8948/1730712131791.png">
<meta property="og:image" content="https://bg51717.github.io/wiki/8948/1730721059917.png">
<meta property="og:image" content="https://bg51717.github.io/wiki/8948/1730721352940.png">
<meta property="og:image" content="https://bg51717.github.io/wiki/8948/1730721428081.png">
<meta property="og:image" content="https://bg51717.github.io/wiki/8948/1730721567241.png">
<meta property="og:image" content="https://bg51717.github.io/wiki/8948/1730721573391.png">
<meta property="og:image" content="https://bg51717.github.io/wiki/8948/1730721660913.png">
<meta property="article:published_time" content="2023-10-23T12:10:11.000Z">
<meta property="article:modified_time" content="2024-11-11T14:10:32.913Z">
<meta property="article:author" content="bg51717">
<meta property="article:tag" content="量化">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://bg51717.github.io/wiki/8948/1698064373146.png">
    

    
        <link rel="alternate" href="/atom.xml" title="Blogs" type="application/atom+xml" />
    

    
        <link rel="icon" href="/wiki/favicon.ico" />
    

    
<link rel="stylesheet" href="/wiki/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/wiki/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/wiki/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/wiki/css/style.css">

    
<script src="/wiki/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/wiki/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/wiki/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/wiki/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/wiki/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Blogs</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/wiki/">首页</a>
                
                    <a class="main-nav-link" href="/wiki/archives">归档</a>
                
                    <a class="main-nav-link" href="/wiki/categories">分类</a>
                
                    <a class="main-nav-link" href="/wiki/tags">标签</a>
                
                    <a class="main-nav-link" href="/wiki/about">关于</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/wiki/',
        CONTENT_URL: '/wiki/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/wiki/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/wiki/">首页</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>分类</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            SmallProjects
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            博客搭建
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/13640/">Hexo+Github搭建个人Wiki风格博客</a></li>  <li class="file"><a href="/wiki/31680/">hexo博客2:双主题</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            huggingface
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/20669/">pytroch_tutorials杂项</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            工具
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/44392/">快速启动工具——utools</a></li>  <li class="file"><a href="/wiki/43151/">文献管理工具zotero</a></li>  <li class="file"><a href="/wiki/61294/">安卓手机配置Google</a></li>  <li class="file"><a href="/wiki/13107/">zsh+powerlevel10K优化终端使用体验</a></li>  <li class="file"><a href="/wiki/13162/">使用dotbot快速同步Linux配置</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            数学
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            代码
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/16846/">数学计算库:SymPy</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            微积分
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/49444/">拉格朗日乘数法解条件极值</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            概率论
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/5656/">信息熵</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            线性代数
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/45525/">矩阵偏分</a></li>  <li class="file"><a href="/wiki/33996/">矩阵奇异值分解SVD</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            杂项
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/20668/">pytroch_tutorials杂项</a></li>  <li class="file"><a href="/wiki/30403/">vscode调试python</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            模板
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/42347/">pytorch_model</a></li>  <li class="file"><a href="/wiki/61054/">PyTorch代码转HF</a></li>  <li class="file"><a href="/wiki/45014/">pytorch分布式-ddp</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            深度学习
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            工程细节
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/7369/">随机数种子</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            经典模块
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/12551/">Adam Optimizer</a></li>  <li class="file"><a href="/wiki/13277/">梯度估计STE</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            自然语言处理
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/5925/">Word2Vec</a></li>  <li class="file"><a href="/wiki/51558/">GloVe</a></li>  <li class="file"><a href="/wiki/26708/">依赖分析Dependency Parsing</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            科研
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            论文阅读
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file active"><a href="/wiki/8948/">论文阅读:BitNet_Scaling_1-bit_Transformers_for_Large_Language_Models</a></li>  <li class="file"><a href="/wiki/62023/">论文阅读:A_Survey_of_Quantization_Methods_for_Efficient_Neural_Network_Inference</a></li>  <li class="file"><a href="/wiki/21264/">llm.int8</a></li>  <li class="file"><a href="/wiki/31769/">大模型量化~GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a></li>  <li class="file"><a href="/wiki/14592/">AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a></li>  <li class="file"><a href="/wiki/341/">OneBit: Towards Extremely Low-bit Large Language Models</a></li>  <li class="file"><a href="/wiki/58958/">OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models</a></li>  <li class="file"><a href="/wiki/22407/">论文阅读习惯</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            自然语言处理
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/63314/">nlp常用排行榜</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            课程资源
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/17140/">readme</a></li>  </ul> 
                    </li> 
                     <li class="file"><a href="/wiki/14261/">Welcome to bg51717's Wiki and Blog</a></li>  </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-科研/论文阅读/论文阅读~BitNet-Scaling-1-bit-Transformers-for-Large-Language-Models" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/wiki/categories/%E7%A7%91%E7%A0%94/">科研</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/wiki/categories/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/wiki/tags/%E9%87%8F%E5%8C%96/" rel="tag">量化</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/wiki/8948/">
            <time datetime="2023-10-23T12:10:11.000Z" itemprop="datePublished">2023-10-23</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/bg51717/Wiki-site/raw/writing/source/_posts/科研/论文阅读/论文阅读~BitNet-Scaling-1-bit-Transformers-for-Large-Language-Models.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/bg51717/Wiki-site/edit/writing/source/_posts/科研/论文阅读/论文阅读~BitNet-Scaling-1-bit-Transformers-for-Large-Language-Models.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/bg51717/Wiki-site/commits/writing/source/_posts/科研/论文阅读/论文阅读~BitNet-Scaling-1-bit-Transformers-for-Large-Language-Models.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            论文阅读:BitNet_Scaling_1-bit_Transformers_for_Large_Language_Models
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">文章目录</strong>
                    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#bitnet"><span class="toc-number">3.</span> <span class="toc-text">BitNet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#bitlinear"><span class="toc-number">3.1.</span> <span class="toc-text">BitLinear</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">3.2.</span> <span class="toc-text">模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ste"><span class="toc-number">3.2.1.</span> <span class="toc-text">STE</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6"><span class="toc-number">3.2.2.</span> <span class="toc-text">混合精度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A2%9E%E5%A4%A7%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="toc-number">3.2.3.</span> <span class="toc-text">增大学习率</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E8%83%BD%E6%95%88"><span class="toc-number">3.3.</span> <span class="toc-text">计算能效</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%8Dtransformer%E5%AF%B9%E6%AF%94"><span class="toc-number">4.</span> <span class="toc-text">16位transformer对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8Eptq%E5%AF%B9%E6%AF%94"><span class="toc-number">5.</span> <span class="toc-text">与PTQ对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C"><span class="toc-number">6.</span> <span class="toc-text">消融实验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">7.</span> <span class="toc-text">代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">8.</span> <span class="toc-text">参考资料</span></a></li></ol>
                </div>
            
        
        
            <h2 id="摘要">摘要</h2>
<p>这篇论文展示了BitNet,一种为大型语言模型设计的可扩展和稳定的1-bit转换器架构。具体地说，引入了BitLinear作为nn.Linar的插入替代,以便从头开始训练1-bit的权重。在语言建模上的实验结果表明，与最先进的8-bit量化方法和FP16
Transformer相比，BitNet在显著降低内存占用和能量消耗的同时，实现了强力的性能。此外，BitNet还展示了一种类似于全精度Transformers的scaling
low，这表明它可以在保持效率和性能效益的同时有效地扩展到更大的语言模型。</p>
<p><img src="/wiki/8948/1698064373146.png"></p>
<p>图1： BitNet从头开始训练1-bit
Transformers，以一种高效的方式获得竞争结果。BitNet明显优于最先进的量化方法。随着模型规模的扩大，成本节约变得更加显著，同时实现与FP16训练的模型的竞争性能。</p>
<h2 id="介绍">介绍</h2>
<p>大模型的推理陈本较高，一个降低成本的重要办法就是量化。</p>
<p>目前LLM的量化方法大多数都是训练后量化PTQ，成本比QAT低但在极低精度表现不好。</p>
<p>LLM量化的另一类方法是量化感知训练QAT，效果更好，但是在低精度下难以收敛。此外，不确定QAT是否遵循scaling
low。</p>
<p>本文首次提出1-bit大模型QAT，提出BitNet，LLM的1-bit
transformer。采用低精度二进制权重和量化激活，同时在训练期间保持优化器状态和梯度的高精度。BitNet
架构的实现非常简单，只需要替换Transformer 中的线性投影（即 PyTorch 中的
nn.Linear）。</p>
<p>在一系列语言建模基准上评测了BitNet。与最先进的量化方法和fp16的baseline相比有竞争力。有效减少了内存占用和能耗。同时遵循类似的scaling
low。</p>
<h2 id="bitnet">BitNet</h2>
<p>模型整体架构图如图所示：</p>
<p><img src="/wiki/8948/1730709381779.png"></p>
<p>相比transformer，使用BitLinear替代原有的Linear和传统的矩阵乘法，其他组件保持高精度，作者认为原因如下：</p>
<ul>
<li>残差连接和层归一化对大型语言模型的计算成本可以忽略不计</li>
<li>随着模型变大，QKV 变换的计算成本比参数投影小得多</li>
<li>保留输入/输出嵌入的精度，因为语言模型必须使用高精度概率来执行采样</li>
</ul>
<h3 id="bitlinear">BitLinear</h3>
<p>BitLinear把权重二值化为+1或-1。在训练的时候，为了保证反向传播的有效性，模型的参数
$ W ^{n m} $是保持高精度的，但是forward的时候会进行量化操作：</p>
<p><span class="math display">\[
\tilde{W} = \text{Sign}(W - \alpha), \quad
\text{Sign}(W_{ij}) = \begin{cases}
+1, &amp; \text{if } W_{ij} &gt; 0, \\
-1, &amp; \text{if } W_{ij} \leq 0,
\end{cases} \quad
\alpha = \frac{1}{nm} \sum_{ij} W_{ij}
\]</span></p>
<p>激活也会量化到$[-Q_{b},Q_{b}] (Q_{b}=2^{b-1})
$，同时添加细致扰动防止clip时溢出：</p>
<p><span class="math display">\[
\tilde{x} = \text{Quant}(x) = \text{Clip}\left( x \times
\frac{Q_b}{\gamma}, -Q_b + \epsilon, Q_b - \epsilon \right) \\
\text{Clip}(x, a, b) = \max(a, \min(b, x)), \quad \gamma = \lVert x
\rVert_{\infty}
\]</span></p>
<p>对于非线性函数之前的激活，会缩放到<span class="math inline">\([0,Q_{b}] (Q_{b}=2^{b-1})\)</span>：</p>
<p><span class="math display">\[
\tilde{x} = \text{Quant}(x) = \text{Clip}\left( (x - \eta) \times
\frac{Q_b}{\gamma}, \epsilon, Q_b - \epsilon \right), \quad \eta =
\min_{ij} x_{ij}
\]</span></p>
<p>其中BitLinear的forward过程为：</p>
<p><span class="math display">\[
\\
\text{LN}(x) = \frac{x - E(x)}{\sqrt{\text{Var}(x)} + \epsilon}, \quad
\beta = \frac{1}{nm} \lVert W \rVert_1 \\
y = \tilde{W} \tilde{x} = \tilde{W} \, \text{Quant}(\text{LN}(x)) \times
\frac{\beta \gamma}{Q_b}
\]</span></p>
<blockquote>
<p>下面这段分析我也不是很理解，一直不知道约等于是怎么来的？</p>
</blockquote>
<p>分析：</p>
<p><span class="math display">\[
\begin{align*}
y &amp;= \tilde{W} \tilde{x} \ ,\\
\text{Var}(y) &amp;= n \, \text{Var}(\tilde{w} \tilde{x}) \\
\quad &amp;= n E[\tilde{w}^2] E[\tilde{x}^2] \\
\quad &amp;= n \beta^2 E[\tilde{x}^2] \approx E[\tilde{x}^2]
\end{align*}
\]</span></p>
<p>当使用归一化操作后，<span class="math inline">\(Var(y) ≈ E[LN(
\tilde{x} )^2] = 1\)</span></p>
<p>同时，为了支持张量并行（一个张量拆分到多卡上），部分参数的需要通过
<code>all-reduce</code>来确定，但是会增加通信成本，因此考虑分组确定，即将权重和激活分为几组，然后独立估计每组的参数：</p>
<p><span class="math display">\[
\alpha_g = \frac{G}{nm} \sum_{ij} W_{ij}^{(g)}, \quad \beta_g =
\frac{G}{nm} \lVert W^{(g)} \rVert_1
\]</span></p>
<h3 id="模型训练">模型训练</h3>
<h4 id="ste">STE</h4>
<p>由于有量化操作不可微分，因此考虑引入<strong>STE</strong>进行梯度的近似。</p>
<h4 id="混合精度">混合精度</h4>
<p>虽然权重和激活被量化为低精度，但梯度和优化器状态以高精度存储，以确保训练的稳定性和准确性。以高精度格式为可学习参数维护一个潜在权重，以累积参数更新。潜在权重在前向传播过程中被动态二值化，并且从不用于推理过程。</p>
<h4 id="增大学习率">增大学习率</h4>
<p>潜在权重的小幅度更新可能不会引起1位权重的变化，为了加速收敛，考虑增大学习率的值。实验表明，BitNet
在收敛方面受益于较大的学习率，而 FP16 Transformer
在相同学习率的训练开始时会发散。</p>
<h3 id="计算能效">计算能效</h3>
<p>论文还给出了理论的计算能效，主要关注矩阵乘法部分。</p>
<p><img src="/wiki/8948/1730712131791.png"></p>
<p>对于transformer里的矩阵乘法，两个矩阵维度分别为<span class="math inline">\(m \times n\)</span>和<span class="math inline">\(n
\times m\)</span>，能效计算公式为：</p>
<p><span class="math display">\[
E_{add} = m \times (n - 1) \times p \times \hat{E}_{add} \\
E_{mul} = m \times n \times p \times \hat{E}_{mul}
\]</span></p>
<p>对于BitNet，矩阵权重为1比特的，因此矩阵乘法的能耗主要由加法决定，和transformer的加法能耗公式相同，而用于放缩的乘法能耗公式为：</p>
<p><span class="math display">\[
E_{mul} = (m \times p + m \times n) \times \hat{E}_{mul}
\]</span></p>
<h2 id="位transformer对比">16位transformer对比</h2>
<p>使用各种规模的 BitNet 训练一系列自回归语言模型，范围从 125M 到
30B。这些模型在英语语料库上进行训练，该语料库由 Pile 数据集、Common
Crawl 快照、RealNews 和 CC-Stories
数据集组成。具体的训练超参可以阅读原文。同时训练作为对比的transformer。</p>
<p>从测试可以发现，模型的loss与transformer相比有类似的scaling low。</p>
<p><img src="/wiki/8948/1730721059917.png"></p>
<p>能耗也有类似的规律。</p>
<p><img src="/wiki/8948/1730721352940.png"></p>
<p>当增大学习率的时候，BitNet可以更好的保持性能。</p>
<p><img src="/wiki/8948/1730721428081.png"></p>
<h2 id="与ptq对比">与PTQ对比</h2>
<p>使用与前文相同的设置训练BitNet和transformer，在训练好的transformer上尝试PTQ量化。</p>
<p>结果如下所示：</p>
<p><img src="/wiki/8948/1730721567241.png"></p>
<p><img src="/wiki/8948/1730721573391.png"></p>
<p>在PPL和Acc上结果明显优于目前最优的PTQ方法。</p>
<h2 id="消融实验">消融实验</h2>
<p>作者还尝试了消融实验：</p>
<p><img src="/wiki/8948/1730721660913.png"></p>
<p>BitNet使用的是
<code>absmax</code>+<code>SubLn</code>。Elastic代表弹性的量化函数，通过可学习的参数动态调整尺度。Pre-LN
是 GPT 相关的默认架构，而 BMT 已被证明可以提高二值化模型的稳定性。</p>
<h2 id="代码">代码</h2>
<p>核心代码文件为：<a target="_blank" rel="noopener" href="https://github.com/kyegomez/BitNet/blob/main/bitnet/bitlinear.py">BitNet/bitnet/bitlinear.py
at main · kyegomez/BitNet</a></p>
<h2 id="参考资料">参考资料</h2>
<blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.11453">BitNet: Scaling 1-bit
Transformers for Large Language Models</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kyegomez/BitNet">kyegomez/BitNet:
Implementation of "BitNet: Scaling 1-bit Transformers for Large Language
Models" in pytorch</a></li>
</ul>
</blockquote>

            </div>
        

        
    
        <section id="comments"> 
        <!-- 公告区域 -->
        <div id="announcement" style="background-color: #f8d7da; color: #721c24; padding: 10px; text-align: center; font-weight: bold; border-radius: 15px;">
            由于评论系统依托于Github的Discuss存在，因此默认评论者会收到所有通知。可以在邮件里点击"unsubscribe"停止接受，后续也可以点击下列仓库进行通知管理：
            <a href="https://github.com/bg51717/Hexo-Blogs-comments" target="_blank" style="color: #0056b3; text-decoration: underline; white-space: nowrap;">
                bg51717/Hexo-Blogs-comments
            </a>
            <br>
            Since the comment system relies on GitHub's Discussions feature, by default, commentators will receive all notifications. You can click "unsubscribe" in the email to stop receiving them, and you can also manage your notifications by clicking on the following repositories:
            <a href="https://github.com/bg51717/Hexo-Blogs-comments" target="_blank" style="color: #0056b3; text-decoration: underline; white-space: nowrap;">
                bg51717/Hexo-Blogs-comments
            </a>
        </div>
        
        <!-- Giscus 评论组件 -->
        <div id="giscus-container"></div>
        <script src="https://giscus.app/client.js"
                data-repo="bg51717/Hexo-Blogs-comments"
                data-repo-id="R_kgDOKhgfLA"
                data-category="General"
                data-category-id="DIC_kwDOKhgfLM4CaPMJ"
                data-mapping="title"
                data-strict="0"
                data-reactions-enabled="1"
                data-emit-metadata="0"
                data-input-position="top"
                data-theme="light"
                data-lang="zh-CN"
                data-loading="lazy"
                crossorigin="anonymous"
                async>
        </script>
        <noscript>请启用 JavaScript 以查看评论。</noscript>
     </section>
    



        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/wiki/43151/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    文献管理工具zotero
                
            </div>
        </a>
    
    
        <a href="/wiki/62023/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">论文阅读:A_Survey_of_Quantization_Methods_for_Efficient_Neural_Network_Inference</div>
        </a>
    
</nav>






<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            bg51717 &copy; 2024 
            <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a target="_blank" rel="noopener" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        <!-- partial('comment/scripts', { page: page })  -->

    
        
<script src="/wiki/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/wiki/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/wiki/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
    
        
    <!-- 引入 KaTeX 的 CSS 文件 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css">
    
    <!-- 引入 KaTeX 的 JS 文件 -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js"></script>

    <script>
        document.addEventListener("DOMContentLoaded", function() {
            // 自动渲染公式
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},  // 行间公式
                    {left: "$", right: "$", display: false},   // 行内公式
                    {left: "\\(", right: "\\)", display: false}, // 行内公式
                    {left: "\\[", right: "\\]", display: true}  // 行间公式
                ],
                ignoredTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],  // 跳过这些标签
                throwOnError: false  // 遇到无法解析的公式时不抛出错误
            });

            // 判断是否需要隐藏滚动条
            var hideScrollbar = false;
            if (hideScrollbar) {
                const katexElements = document.querySelectorAll('.katex-display');
                katexElements.forEach(function(el) {
                    el.style.overflowX = 'hidden';
                });
            }

            // 给含有 KaTeX 公式的元素添加类名 'has-katex'，类似 MathJax 的 'has-jax'
            var katexElements = document.querySelectorAll('.katex');
            katexElements.forEach(function(el) {
                el.classList.add('has-katex');
            });
        });
    </script>


    



<!-- Custom Scripts -->

<script src="/wiki/js/main.js"></script>


    </div>
</body>
</html>